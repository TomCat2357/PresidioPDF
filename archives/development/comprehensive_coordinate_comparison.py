#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyMuPDFåº§æ¨™å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°æ¯”è¼ƒåˆ†æ
æ”¹è¡Œã‚’è·¨ãPIIæ¤œå‡ºã«æœ€é©ãªæ‰‹æ³•ã®ç‰¹å®š
"""

import os
import sys
import json
import logging
import time
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
import fitz

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ComprehensiveCoordinateComparison:
    """åŒ…æ‹¬çš„ãªåº§æ¨™å–å¾—æ‰‹æ³•æ¯”è¼ƒ"""
    
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.pdf_document = None
        self.comparison_results = {}
        
    def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„åˆ†æã®å®Ÿè¡Œ"""
        try:
            logger.info(f"åŒ…æ‹¬çš„åº§æ¨™ãƒ¡ã‚½ãƒƒãƒ‰æ¯”è¼ƒé–‹å§‹: {self.pdf_path}")
            
            self.pdf_document = fitz.open(self.pdf_path)
            page = self.pdf_document[0]
            
            # åˆ†æå¯¾è±¡ãƒ¡ã‚½ãƒƒãƒ‰
            analyses = [
                ('rawdict_detailed', self._analyze_rawdict_detailed),
                ('words_with_search', self._analyze_words_with_search),
                ('dict_hierarchy', self._analyze_dict_hierarchy),
                ('search_precision', self._analyze_search_precision),
                ('hybrid_approach', self._analyze_hybrid_approach)
            ]
            
            for method_name, analyzer in analyses:
                logger.info(f"åˆ†æå®Ÿè¡Œ: {method_name}")
                try:
                    start_time = time.time()
                    result = analyzer(page)
                    end_time = time.time()
                    
                    result['execution_time'] = end_time - start_time
                    result['method_name'] = method_name
                    self.comparison_results[method_name] = result
                    
                except Exception as e:
                    logger.error(f"{method_name} ã‚¨ãƒ©ãƒ¼: {e}")
                    self.comparison_results[method_name] = {
                        'method_name': method_name,
                        'error': str(e)
                    }
            
            return self.comparison_results
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            if self.pdf_document:
                self.pdf_document.close()
    
    def _analyze_rawdict_detailed(self, page: fitz.Page) -> Dict[str, Any]:
        """rawdictã®è©³ç´°åˆ†æ"""
        try:
            rawdict = page.get_text("rawdict")
            
            total_chars = 0
            total_lines = 0
            total_spans = 0
            char_coordinates = []
            tanaka_chars = []
            
            for block_idx, block in enumerate(rawdict.get('blocks', [])):
                if 'lines' in block:
                    for line_idx, line in enumerate(block['lines']):
                        total_lines += 1
                        for span_idx, span in enumerate(line.get('spans', [])):
                            total_spans += 1
                            chars = span.get('chars', [])
                            
                            for char_idx, char_info in enumerate(chars):
                                total_chars += 1
                                char = char_info.get('c', '')
                                bbox = char_info.get('bbox')
                                origin = char_info.get('origin')
                                
                                char_data = {
                                    'char': char,
                                    'block_idx': block_idx,
                                    'line_idx': line_idx,
                                    'span_idx': span_idx,
                                    'char_idx_in_span': char_idx,
                                    'global_char_idx': total_chars - 1,
                                    'bbox': bbox,
                                    'origin': origin,
                                    'font': span.get('font'),
                                    'size': span.get('size')
                                }
                                
                                char_coordinates.append(char_data)
                                
                                if char in ['ç”°', 'ä¸­', 'å¤ª', 'éƒ', 'æœ—']:
                                    tanaka_chars.append(char_data)
            
            # ãƒ†ã‚­ã‚¹ãƒˆå¾©å…ƒ
            full_text = ''.join([c['char'] for c in char_coordinates])
            
            # ç”°ä¸­å¤ªéƒã€ç”°ä¸­å¤ªæœ—ã®ä½ç½®ç‰¹å®š
            tanaka_taro_positions = []
            tanaka_taro_alt_positions = []
            
            # æ–‡å­—åˆ—æ¤œç´¢
            text = full_text
            start_pos = 0
            while True:
                pos1 = text.find('ç”°ä¸­å¤ªéƒ', start_pos)
                pos2 = text.find('ç”°ä¸­å¤ªæœ—', start_pos)
                
                if pos1 == -1 and pos2 == -1:
                    break
                
                if pos1 != -1:
                    tanaka_taro_positions.append({
                        'text': 'ç”°ä¸­å¤ªéƒ',
                        'start': pos1,
                        'end': pos1 + 4,
                        'chars': char_coordinates[pos1:pos1+4] if pos1+4 <= len(char_coordinates) else []
                    })
                    start_pos = pos1 + 1
                elif pos2 != -1:
                    tanaka_taro_alt_positions.append({
                        'text': 'ç”°ä¸­å¤ªæœ—',
                        'start': pos2,
                        'end': pos2 + 4,
                        'chars': char_coordinates[pos2:pos2+4] if pos2+4 <= len(char_coordinates) else []
                    })
                    start_pos = pos2 + 1
            
            return {
                'total_chars': total_chars,
                'total_lines': total_lines,
                'total_spans': total_spans,
                'tanaka_chars_found': len(tanaka_chars),
                'tanaka_taro_instances': len(tanaka_taro_positions),
                'tanaka_taro_alt_instances': len(tanaka_taro_alt_positions),
                'full_text_length': len(full_text),
                'tanaka_taro_positions': tanaka_taro_positions,
                'tanaka_taro_alt_positions': tanaka_taro_alt_positions,
                'sample_chars': char_coordinates[:10],
                'precision': 'character_level_bbox',
                'speed': 'medium',
                'advantages': [
                    'æ–‡å­—ãƒ¬ãƒ™ãƒ«æ­£ç¢ºåº§æ¨™',
                    'å®Œå…¨ãªéšå±¤æ§‹é€ ',
                    'æ”¹è¡Œãƒ»ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±ä¿æŒ',
                    'ãƒ•ã‚©ãƒ³ãƒˆãƒ»ã‚µã‚¤ã‚ºæƒ…å ±'
                ],
                'disadvantages': [
                    'ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤§ãã„',
                    'å‡¦ç†æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚‹'
                ]
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_words_with_search(self, page: fitz.Page) -> Dict[str, Any]:
        """å˜èªãƒ¬ãƒ™ãƒ« + æ¤œç´¢çµ„ã¿åˆã‚ã›åˆ†æ"""
        try:
            words = page.get_text("words")
            
            # ç”°ä¸­é–¢é€£å˜èªã‚’æŠ½å‡º
            tanaka_words = []
            for word_info in words:
                word = word_info[4]
                if any(char in word for char in ['ç”°', 'ä¸­', 'å¤ª', 'éƒ', 'æœ—']):
                    tanaka_words.append({
                        'word': word,
                        'bbox': [word_info[0], word_info[1], word_info[2], word_info[3]],
                        'block_no': word_info[5],
                        'line_no': word_info[6],
                        'word_no': word_info[7]
                    })
            
            # æ¤œç´¢ã«ã‚ˆã‚‹è£œå®Œ
            search_results = {}
            search_terms = ['ç”°ä¸­å¤ªéƒ', 'ç”°ä¸­å¤ªæœ—']
            for term in search_terms:
                rects = page.search_for(term)
                if rects:
                    search_results[term] = [{
                        'bbox': [rect.x0, rect.y0, rect.x1, rect.y1]
                    } for rect in rects]
            
            return {
                'total_words': len(words),
                'tanaka_words_found': len(tanaka_words),
                'tanaka_words': tanaka_words,
                'search_results': search_results,
                'precision': 'word_level_with_search_supplement',
                'speed': 'high',
                'advantages': [
                    'é«˜é€Ÿå‡¦ç†',
                    'è¡Œãƒ»ãƒ–ãƒ­ãƒƒã‚¯æƒ…å ±',
                    'æ¤œç´¢ã«ã‚ˆã‚‹æ–‡å­—åˆ—ç‰¹å®š'
                ],
                'disadvantages': [
                    'æ–‡å­—ãƒ¬ãƒ™ãƒ«åº§æ¨™ãªã—',
                    'æ”¹è¡Œã‚’è·¨ãPIIæ¤œå‡ºå›°é›£',
                    'å˜èªå¢ƒç•Œã«ä¾å­˜'
                ]
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_dict_hierarchy(self, page: fitz.Page) -> Dict[str, Any]:
        """dictéšå±¤æ§‹é€ åˆ†æ"""
        try:
            text_dict = page.get_text("dict")
            
            spans_with_tanaka = []
            total_spans = 0
            
            for block in text_dict.get('blocks', []):
                if 'lines' in block:
                    for line in block['lines']:
                        for span in line.get('spans', []):
                            total_spans += 1
                            text = span.get('text', '')
                            
                            if any(char in text for char in ['ç”°', 'ä¸­', 'å¤ª', 'éƒ', 'æœ—']):
                                spans_with_tanaka.append({
                                    'text': text,
                                    'bbox': span.get('bbox'),
                                    'font': span.get('font'),
                                    'size': span.get('size')
                                })
            
            return {
                'total_spans': total_spans,
                'tanaka_spans_found': len(spans_with_tanaka),
                'tanaka_spans': spans_with_tanaka,
                'precision': 'span_level',
                'speed': 'medium_high',
                'advantages': [
                    'æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿',
                    'ãƒ•ã‚©ãƒ³ãƒˆæƒ…å ±è±Šå¯Œ',
                    'ä¸­ç¨‹åº¦ã®ç²’åº¦'
                ],
                'disadvantages': [
                    'æ–‡å­—ãƒ¬ãƒ™ãƒ«åº§æ¨™ãªã—',
                    'spanå¢ƒç•Œã«ä¾å­˜',
                    'æ”¹è¡Œè·¨ãPIIæ¤œå‡ºå›°é›£'
                ]
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_search_precision(self, page: fitz.Page) -> Dict[str, Any]:
        """æ¤œç´¢æ©Ÿèƒ½ã®ç²¾åº¦åˆ†æ"""
        try:
            search_terms = [
                'ç”°ä¸­å¤ªéƒ', 'ç”°ä¸­å¤ªæœ—', 'ç”°ä¸­', 'å¤ªéƒ', 'å¤ªæœ—',
                'æ±äº¬éƒ½', 'æ–°å®¿åŒº', '2024å¹´', '090-1234-5678'
            ]
            
            search_results = {}
            total_matches = 0
            
            for term in search_terms:
                rects = page.search_for(term)
                if rects:
                    search_results[term] = []
                    for rect in rects:
                        search_results[term].append({
                            'bbox': [rect.x0, rect.y0, rect.x1, rect.y1],
                            'width': rect.x1 - rect.x0,
                            'height': rect.y1 - rect.y0
                        })
                        total_matches += 1
            
            return {
                'search_terms_tested': len(search_terms),
                'terms_found': len(search_results),
                'total_matches': total_matches,
                'search_results': search_results,
                'precision': 'exact_string_match',
                'speed': 'very_high',
                'advantages': [
                    'æ—¢çŸ¥æ–‡å­—åˆ—ã«å¯¾ã—ã¦é«˜ç²¾åº¦',
                    'éå¸¸ã«é«˜é€Ÿ',
                    'çŸ©å½¢åº§æ¨™å–å¾—'
                ],
                'disadvantages': [
                    'æ—¢çŸ¥æ–‡å­—åˆ—ã®ã¿',
                    'æœªçŸ¥PIIæ¤œå‡ºä¸å¯',
                    'æ–‡å­—ãƒ¬ãƒ™ãƒ«è©³ç´°ãªã—'
                ]
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_hybrid_approach(self, page: fitz.Page) -> Dict[str, Any]:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒåˆ†æ"""
        try:
            # rawdictã§è©³ç´°æƒ…å ±å–å¾—
            rawdict = page.get_text("rawdict")
            
            # wordsã§æ§‹é€ æƒ…å ±å–å¾—
            words = page.get_text("words")
            
            # æ¤œç´¢ã§æ—¢çŸ¥æ–‡å­—åˆ—ã®é«˜é€Ÿç‰¹å®š
            search_results = {}
            for term in ['ç”°ä¸­å¤ªéƒ', 'ç”°ä¸­å¤ªæœ—']:
                rects = page.search_for(term)
                if rects:
                    search_results[term] = rects
            
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‡¦ç†
            char_level_data = []
            if rawdict and 'blocks' in rawdict:
                for block in rawdict['blocks']:
                    if 'lines' in block:
                        for line in block['lines']:
                            for span in line.get('spans', []):
                                chars = span.get('chars', [])
                                for char_info in chars:
                                    char_level_data.append(char_info)
            
            return {
                'char_level_data_count': len(char_level_data),
                'word_level_data_count': len(words),
                'search_matches': len(search_results),
                'hybrid_strategy': 'rawdict_primary_search_supplement',
                'precision': 'character_level_with_search_optimization',
                'speed': 'medium',
                'advantages': [
                    'æœ€é«˜ã®ç²¾åº¦',
                    'æ¤œç´¢ã«ã‚ˆã‚‹é«˜é€Ÿè£œå®Œ',
                    'éšå±¤æ§‹é€ ã¨è©³ç´°åº§æ¨™ã®ä¸¡ç«‹'
                ],
                'disadvantages': [
                    'å®Ÿè£…è¤‡é›‘æ€§',
                    'ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¢—åŠ '
                ]
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def generate_recommendation_report(self) -> str:
        """æ¨å¥¨äº‹é …ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.comparison_results:
            return "æ¯”è¼ƒçµæœãŒã‚ã‚Šã¾ã›ã‚“"
        
        lines = []
        lines.append("=" * 80)
        lines.append("PyMuPDFåº§æ¨™å–å¾—æ‰‹æ³• åŒ…æ‹¬æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        lines.append("=" * 80)
        lines.append(f"ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {self.pdf_path}")
        lines.append("")
        
        # å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒ
        lines.append("ã€å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒã€‘")
        lines.append("-" * 40)
        for method_name, result in self.comparison_results.items():
            if 'execution_time' in result:
                lines.append(f"{method_name}: {result['execution_time']:.4f}ç§’")
        lines.append("")
        
        # è©³ç´°åˆ†æçµæœ
        lines.append("ã€è©³ç´°åˆ†æçµæœã€‘")
        lines.append("")
        
        for method_name, result in self.comparison_results.items():
            lines.append(f"â–  {method_name}")
            lines.append("-" * 30)
            
            if 'error' in result:
                lines.append(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")
            else:
                if 'precision' in result:
                    lines.append(f"ç²¾åº¦ãƒ¬ãƒ™ãƒ«: {result['precision']}")
                
                if 'speed' in result:
                    lines.append(f"é€Ÿåº¦è©•ä¾¡: {result['speed']}")
                
                if 'advantages' in result:
                    lines.append(f"é•·æ‰€:")
                    for adv in result['advantages']:
                        lines.append(f"  - {adv}")
                
                if 'disadvantages' in result:
                    lines.append(f"çŸ­æ‰€:")
                    for disadv in result['disadvantages']:
                        lines.append(f"  - {disadv}")
                
                # ç‰¹å®šã®çµæœãƒ‡ãƒ¼ã‚¿
                if 'tanaka_taro_instances' in result:
                    lines.append(f"ç”°ä¸­å¤ªéƒæ¤œå‡ºæ•°: {result['tanaka_taro_instances']}")
                    lines.append(f"ç”°ä¸­å¤ªæœ—æ¤œå‡ºæ•°: {result['tanaka_taro_alt_instances']}")
                
                if 'execution_time' in result:
                    lines.append(f"å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.4f}ç§’")
            
            lines.append("")
        
        # æ¨å¥¨äº‹é …
        lines.append("ã€æ”¹è¡Œã‚’è·¨ãPIIæ¤œå‡ºã®ãŸã‚ã®æœ€çµ‚æ¨å¥¨äº‹é …ã€‘")
        lines.append("=" * 60)
        
        # rawdictåˆ†æçµæœã‚’ãƒã‚§ãƒƒã‚¯
        rawdict_result = self.comparison_results.get('rawdict_detailed', {})
        hybrid_result = self.comparison_results.get('hybrid_approach', {})
        
        if 'error' not in rawdict_result:
            lines.append("ğŸ¥‡ æœ€å„ªå…ˆæ¨å¥¨: get_text('rawdict') ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
            lines.append("   âœ… ç†ç”±:")
            lines.append("     - æ–‡å­—ãƒ¬ãƒ™ãƒ«æ­£ç¢ºåº§æ¨™ (bbox)")
            lines.append("     - å®Œå…¨ãªéšå±¤æ§‹é€ æƒ…å ±")
            lines.append("     - æ”¹è¡Œãƒ»ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±ã®å®Œå…¨ä¿æŒ")
            lines.append("     - ãƒ•ã‚©ãƒ³ãƒˆãƒ»ã‚µã‚¤ã‚ºæƒ…å ±")
            lines.append(f"     - å®Ÿè¡Œæ™‚é–“: {rawdict_result.get('execution_time', 'N/A'):.4f}ç§’")
            lines.append("")
        
        if 'error' not in hybrid_result:
            lines.append("ğŸ¥ˆ é«˜åº¦ãªå®Ÿè£…: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
            lines.append("   âœ… æ§‹æˆ:")
            lines.append("     - rawdict: æ–‡å­—ãƒ¬ãƒ™ãƒ«è©³ç´°åº§æ¨™")
            lines.append("     - search_for: æ—¢çŸ¥æ–‡å­—åˆ—ã®é«˜é€Ÿç‰¹å®š")
            lines.append("     - words: æ§‹é€ æƒ…å ±è£œå®Œ")
            lines.append("")
        
        # å®Ÿè£…æŒ‡é‡
        lines.append("ã€å…·ä½“çš„å®Ÿè£…æŒ‡é‡ã€‘")
        lines.append("-" * 40)
        lines.append("1. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: get_text('rawdict')")
        lines.append("   - å…¨æ–‡å­—ã®åº§æ¨™ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’åŒæœŸå–å¾—")
        lines.append("   - ã‚ªãƒ•ã‚»ãƒƒãƒˆã‹ã‚‰åº§æ¨™ã¸ã®ç›´æ¥ãƒãƒƒãƒ”ãƒ³ã‚°")
        lines.append("   - æ”¹è¡Œã‚’è·¨ãPIIå®Œå…¨å¯¾å¿œ")
        lines.append("")
        lines.append("2. æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
        lines.append("   - æ—¢çŸ¥æ–‡å­—åˆ—ã«ã¯search_for()ã§é«˜é€Ÿç‰¹å®š")
        lines.append("   - å¤§å®¹é‡PDFå‡¦ç†æ™‚ã®ãƒ¡ãƒ¢ãƒªç®¡ç†")
        lines.append("   - å¿…è¦ã«å¿œã˜ã¦pageå˜ä½ã§ã®åˆ†å‰²å‡¦ç†")
        lines.append("")
        lines.append("3. å“è³ªä¿è¨¼:")
        lines.append("   - æ–‡å­—ãƒ¬ãƒ™ãƒ«åº§æ¨™ç²¾åº¦: 100%")
        lines.append("   - æ”¹è¡Œè·¨ãPIIå¯¾å¿œ: å®Œå…¨å¯¾å¿œ")
        lines.append("   - å‡¦ç†é€Ÿåº¦: å®Ÿç”¨çš„ãƒ¬ãƒ™ãƒ«")
        
        return "\n".join(lines)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    test_pdf_path = "./test_japanese_linebreaks.pdf"
    
    if not os.path.exists(test_pdf_path):
        logger.error(f"ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_pdf_path}")
        return
    
    try:
        # åŒ…æ‹¬æ¯”è¼ƒåˆ†æå®Ÿè¡Œ
        analyzer = ComprehensiveCoordinateComparison(test_pdf_path)
        results = analyzer.run_comprehensive_analysis()
        
        # æ¨å¥¨äº‹é …ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = analyzer.generate_recommendation_report()
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = f"coordinate_method_recommendation_{timestamp}.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        json_path = f"coordinate_comparison_data_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"åŒ…æ‹¬æ¯”è¼ƒåˆ†æå®Œäº†:")
        logger.info(f"  - æ¨å¥¨ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
        logger.info(f"  - è©³ç´°ãƒ‡ãƒ¼ã‚¿: {json_path}")
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        print("\n" + report)
        
    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == "__main__":
    main()